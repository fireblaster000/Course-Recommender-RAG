{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, Docx2txtLoader\n",
    "from pathlib import Path\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from langchain.memory import ConversationSummaryBufferMemory,ConversationBufferMemory, ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import create_retrieval_chain, RetrievalQA, ConversationalRetrievalChain, RetrievalQAWithSourcesChain\n",
    "\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_VECTOR_STORE_DIR = Path('./data')\n",
    "# get hugging face API key from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchain_document_loader(TMP_DIR):\n",
    "    \"\"\"\n",
    "    Load documents from the temporary directory (TMP_DIR). \n",
    "    Files can be in txt, pdf, CSV or docx format.\n",
    "    \"\"\"\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # txt_loader = DirectoryLoader(\n",
    "    #     TMP_DIR.as_posix(), glob=\"**/*.txt\", loader_cls=TextLoader, show_progress=True\n",
    "    # )\n",
    "    # documents.extend(txt_loader.load())\n",
    "\n",
    "    # pdf_loader = DirectoryLoader(\n",
    "    #     TMP_DIR.as_posix(), glob=\"**/*.pdf\", loader_cls=PyPDFLoader, show_progress=True\n",
    "    # )\n",
    "    # documents.extend(pdf_loader.load())\n",
    "\n",
    "    # csv_loader = DirectoryLoader(\n",
    "    #     TMP_DIR.as_posix(), glob=\"**/*.csv\", loader_cls=CSVLoader, show_progress=True,\n",
    "    #     loader_kwargs={\"encoding\":\"utf8\"}\n",
    "    # )\n",
    "    # documents.extend(csv_loader.load())\n",
    "\n",
    "    doc_loader = DirectoryLoader(\n",
    "        TMP_DIR.as_posix(),\n",
    "        glob=\"**/*.docx\",\n",
    "        loader_cls=Docx2txtLoader,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    documents.extend(doc_loader.load())\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [00:05<00:00, 54.36it/s]\n"
     ]
    }
   ],
   "source": [
    "directory_path = 'course reviews'\n",
    "TMP_DIR = Path(directory_path)\n",
    "documents = langchain_document_loader(TMP_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Year of study: Junior\\n\\nEcon 100\\nEcon 100 is one of the most fun, intuitive course I took. It gives insights into the world if economics without overwhelming the students. The course delved into some basic Economic models, their applications. The graded instruments were nicely segmented with a well defined outline. The instructor, though some times can feel very standoffish, is no doubt a great instructor if not great human.\\n\\nGpa: Not yet completed one.' metadata={'source': 'course reviews\\\\Student_10_Course_100.docx'}\n",
      "295\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_embedding_model():\n",
    "    embedding = OllamaEmbeddings(model='nomic-embed-text')\n",
    "    return embedding\n",
    "\n",
    "embeddings_nomic = select_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(embeddings,documents,vectorstore_name):\n",
    "    \"\"\"Create a Chroma vector database.\"\"\"\n",
    "    persist_directory = (LOCAL_VECTOR_STORE_DIR.as_posix() + \"/\" + vectorstore_name)\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarty of sentences (0, 1): 331.425\n",
      "Similarty of sentences (0, 2): 120.974\n",
      "Similarty of sentences (1, 2): 170.213\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = [\"I like pets.\",\n",
    "             \"Pets bring joy to our lives.\",\n",
    "             \"Langchain is a framework for developing applications powered by LLMs.\"]\n",
    "\n",
    "# 1. Calculate embedding vectors\n",
    "embedding_vectors = [embeddings_nomic.embed_query(sentence) for sentence in sentences]\n",
    "\n",
    "for combination in list(combinations(range(len(sentences)),2)):\n",
    "    # 2. Calculate similarity using dot product from numpy:\n",
    "    dot_prodduct = round(np.dot(embedding_vectors[combination[0]], embedding_vectors[combination[1]]),3)\n",
    "    print(f\"Similarty of sentences {combination}: {dot_prodduct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_vectorstores = False # change to True to create vectorstores\n",
    "\n",
    "if create_vectorstores:\n",
    "    vector_store_nomic = create_vectorstore(embeddings_nomic,documents,\"vector_store_nomic\")\n",
    "    print(\"Vector store created\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_store_Ollama: 429 chunks.\n"
     ]
    }
   ],
   "source": [
    "vector_store_nomic = Chroma(persist_directory = LOCAL_VECTOR_STORE_DIR.as_posix() + \"/vector_store_nomic\", \n",
    "                            embedding_function=embeddings_nomic)\n",
    "print(\"vector_store_Ollama:\",vector_store_nomic._collection.count(),\"chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_documents(docs,search_with_score=False):\n",
    "    \"\"\"helper function to print documents.\"\"\"\n",
    "    if search_with_score:\n",
    "        # used for similarity_search_with_score\n",
    "        print(\n",
    "            f\"\\n{'-' * 100}\\n\".join(\n",
    "                [f\"Document {i+1}:\\n\\n\" + doc[0].page_content +\"\\n\\nscore:\"+str(round(doc[-1],3))+\"\\n\" \n",
    "                 for i, doc in enumerate(docs)]\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        # used for similarity_search or max_marginal_relevance_search\n",
    "        print(\n",
    "            f\"\\n{'-' * 100}\\n\".join(\n",
    "                [f\"Document {i+1}:\\n\\n\" + doc.page_content \n",
    "                 for i, doc in enumerate(docs)]\n",
    "            )\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 200 level course:\n",
      "\n",
      "CS 202\n",
      "Data Structures with Sir Ihsan was a challenging yet fun course. I learned a lot and the course challenges your ability to think and rationalize. Learning wise, this course is great. The outline is well defined and you already know the quiz schedule before the semester so that helps you set your schedule before hand. There is no midterm either which helps during the midweek by lessening the burden. The assignments are comparatively easier but still challenging enough. \n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "\n",
      "score:375.154\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 200 level course:\n",
      "\n",
      "CS 202\n",
      "Data Structures with Sir Ihsan was a challenging yet fun course. I learned a lot and the course challenges your ability to think and rationalize. Learning wise, this course is great. The outline is well defined and you already know the quiz schedule before the semester so that helps you set your schedule before hand. There is no midterm either which helps during the midweek by lessening the burden. The assignments are comparatively easier but still challenging enough. \n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "\n",
      "score:375.187\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Year of study: Senior\n",
      "\n",
      "CS100 - Computational Problem Solving\n",
      "This is a very slow and repetitive course. It takes too long to get to the meat of the content and there is a huge lag in between the labs and the lecture content. The labs and assignments were laughably easy which meant the grading ended up being terrible, with ridiculously high means. Would only recommend if someone plans to pursue a CS minor.\n",
      "\n",
      "Gpa: CS437 - Deep Learning\n",
      "This course is very hit or miss for students. I personally didn't like it since I felt that the instructor never made the effort to teach concepts in depth, or to excite the students in what they were learning. The TAs for this course were garbage in that they created assignments that were very redundant and required too much donkey work and didn't require much intellectual thought to them. There wasn't much learning in this and it all felt very rushed. Getting a grade wasn't that difficult since it was honestly just about putting in the hours.\n",
      "\n",
      "score:396.844\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Year of study: Senior\n",
      "\n",
      "1) 𝑰𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒕𝒊𝒐𝒏 𝒕𝒐 𝒐𝒃𝒋𝒆𝒄𝒕 𝒐𝒓𝒊𝒆𝒏𝒕𝒆𝒅 𝒑𝒓𝒐𝒈𝒓𝒂𝒎𝒎𝒊𝒏𝒈 (𝑪𝒔200)\n",
      "2) CS 200 with Dr. Awais is an easy A. He is very lenient but he teaches a bit slow so expect just average learning (we had to listen to him on 2x but idk if it will be possible if its on campus)\n",
      "3) Course difficulty was a 3.\n",
      "\n",
      "Gpa: 1)  𝑰𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒕𝒊𝒐𝒏 𝒕𝒐 𝒐𝒃𝒋𝒆𝒄𝒕 𝒐𝒓𝒊𝒆𝒏𝒕𝒆𝒅 𝒑𝒓𝒐𝒈𝒓𝒂𝒎𝒎𝒊𝒏𝒈 (𝑪𝒔200)\n",
      "2) Shafay teaches very well in terms of theory, concepts, backend, and the market usage.\n",
      "However, he doesn't focus mainly on the coding part. So, you have to learn the coding and keep practicing yourself.\n",
      "Labs:\n",
      "Labs are a bit hard in the start but gradually the difficulty level decreases. This is just to build in the passion to practice in you. Sadly, Shafay is the only instructor who gives individual time for every lab task. So, you should have a good coding speed. If you don't have know, not an issue; will learn gradually in his course.\n",
      "Quizzes:\n",
      "Quizzes are normal. Like if you have attended classes and just have seen his resources slides/pdf one day before, good to go in the quiz. (Easy quizzes)\n",
      "Assignments:\n",
      "The assignments depend on TAs but Shafay ask them to have a bit difficult one. But in the end, ho jati hein.\n",
      "Classes:\n",
      "The most important part of any course with Shafay is his classes. He teaches very well and test you according to it. Please don't miss classes and never hesitate to ask questions.\n",
      "\n",
      "3) Course difficulty was a 4.\n",
      "\n",
      "score:400.395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get most similar documents - with scores \n",
    "# Here, we use Cosine Similarity. So a lower score is better.\n",
    "\n",
    "query = 'What are some difficult CS courses?'\n",
    "docs_withScores = vector_store_nomic.similarity_search_with_score(query,k=4)\n",
    "\n",
    "print_documents(docs_withScores,search_with_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarty of document_0 to the query: 190.1584\n",
      "Similarty of document_1 to the query: 190.1584\n",
      "Similarty of document_2 to the query: 209.8965\n",
      "Similarty of document_3 to the query: 206.0805\n"
     ]
    }
   ],
   "source": [
    "query_embeddings = embeddings_nomic.embed_query(query)\n",
    "docs_embeddings = embeddings_nomic.embed_documents(\n",
    "    [docs_withScores[i][0].page_content \n",
    "     for i in range(len(docs_withScores))\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i in range(len(docs_embeddings)):\n",
    "    dot_product = round(np.dot(query_embeddings, docs_embeddings[i]),4)\n",
    "    print(f\"Similarty of document_{i} to the query: {dot_product}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorstore_backed_retriever(vectorstore,search_type=\"similarity\",k=4,score_threshold=None):\n",
    "    \"\"\"create a vectorsore-backed retriever\n",
    "    Parameters: \n",
    "        search_type: Defines the type of search that the Retriever should perform.\n",
    "            Can be \"similarity\" (default), \"mmr\", or \"similarity_score_threshold\"\n",
    "        k: number of documents to return (Default: 4) \n",
    "        score_threshold: Minimum relevance threshold for similarity_score_threshold (default=None)\n",
    "    \"\"\"\n",
    "    search_kwargs={}\n",
    "    if k is not None:\n",
    "        search_kwargs['k'] = k\n",
    "    if score_threshold is not None:\n",
    "        search_kwargs['score_threshold'] = score_threshold\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=search_type,\n",
    "        search_kwargs=search_kwargs\n",
    "    )\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 200 level course:\n",
      "\n",
      "CS 202\n",
      "Data Structures with Sir Ihsan was a challenging yet fun course. I learned a lot and the course challenges your ability to think and rationalize. Learning wise, this course is great. The outline is well defined and you already know the quiz schedule before the semester so that helps you set your schedule before hand. There is no midterm either which helps during the midweek by lessening the burden. The assignments are comparatively easier but still challenging enough. \n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 200 level course:\n",
      "\n",
      "CS 202\n",
      "Data Structures with Sir Ihsan was a challenging yet fun course. I learned a lot and the course challenges your ability to think and rationalize. Learning wise, this course is great. The outline is well defined and you already know the quiz schedule before the semester so that helps you set your schedule before hand. There is no midterm either which helps during the midweek by lessening the burden. The assignments are comparatively easier but still challenging enough. \n",
      "\n",
      "Gpa: 3.60-4.00\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "CA 437 - Deep Learrning. Intellectually challenging and stimulating. Dl introduces the many used practical applications of different algorithms. The course, up until now, has thoroughly tested our understanding of different concepts and its application in coding. Very good and practical course\n",
      "\n",
      "Gpa: CA 437 - Deep Learrning. Intellectually challenging and stimulating. Dl introduces the many used practical applications of different algorithms. The course, up until now, has thoroughly tested our understanding of different concepts and its application in coding. Very good and practical course\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Year of study: Junior\n",
      "\n",
      "Review for 400 level course:\n",
      "\n",
      "CA 437 - Deep Learrning. Intellectually challenging and stimulating. Dl introduces the many used practical applications of different algorithms. The course, up until now, has thoroughly tested our understanding of different concepts and its application in coding. Very good and practical course\n",
      "\n",
      "Gpa: 3.30-3.60\n"
     ]
    }
   ],
   "source": [
    "# Similarity search\n",
    "retriever = Vectorstore_backed_retriever(vector_store_nomic,search_type=\"similarity\",k=4)\n",
    "\n",
    "# Get relevant documents\n",
    "\n",
    "query = 'What are some intellectually challenging and stimulating courses?'\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "print_documents(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "def instantiate_LLM(api_key,temperature=0.5,top_p=0.95,model_name=None):\n",
    "    \"\"\"Instantiate LLM in Langchain.\n",
    "    Parameters:\n",
    "        LLM_provider (str): the LLM provider; in [\"OpenAI\",\"Google\",\"HuggingFace\"]\n",
    "        model_name (str): in [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-0125\", \"gpt-4-turbo-preview\", \n",
    "            \"gemini-pro\", \"mistralai/Mistral-7B-Instruct-v0.2\"].            \n",
    "        api_key (str): google_api_key or openai_api_key or huggingfacehub_api_token \n",
    "        temperature (float): Range: 0.0 - 1.0; default = 0.5\n",
    "        top_p (float): : Range: 0.0 - 1.0; default = 1.\n",
    "    \"\"\"\n",
    "    \n",
    "  \n",
    "    llm = HuggingFaceHub(\n",
    "        repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", \n",
    "        # repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\", \n",
    "        # repo_id=model_name,\n",
    "        huggingfacehub_api_token=api_key,\n",
    "        model_kwargs={\n",
    "            \"temperature\":temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"do_sample\": True,\n",
    "            \"max_new_tokens\":1024,\n",
    "        },\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "HUGGINGFACE_API_KEY = os.getenv(\"HUGGING_FACE_API_KEY\")\n",
    "llm = instantiate_LLM(api_key=HUGGINGFACE_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_memory():\n",
    "    \"\"\"Creates a ConversationSummaryBufferMemory for our model\n",
    "    Creates a ConversationBufferWindowMemory for our models.\"\"\"\n",
    "    \n",
    "    memory = ConversationBufferWindowMemory(\n",
    "        memory_key=\"history\",\n",
    "        input_key=\"question\",\n",
    "        return_messages=True,\n",
    "        k=2\n",
    "    )\n",
    "\n",
    "    return memory\n",
    "\n",
    "memory = create_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"question\": \"What can you do?\"},\n",
    "    {\"output\": \"I can answer queries based on the past reviews and course outlines of various courses offered at LUMS.\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_qa = \"\"\"\n",
    "You are a professional chatbot assistant for helping students at LUMS regarding course selection.\n",
    "\n",
    "Please follow the following rules:\n",
    "\n",
    "1. Answer the question in your own words from the context given to you.\n",
    "2. If you don't know the answer, don't try to make up an answer.\n",
    "3. If you don't have a course's review or outline, just say that you do not know about this course.\n",
    "4. If a user enters a course code (e.g. ECON100 or CS370), match it with reviews with that course code. If the user enters a course name (e.g. Introduction to Economics or Database Systems), match it with reviews with that course name.\n",
    "5. If the user is not asking about a course, ignore the context and answer the question based on your general knowledge.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "You are having a converation with a student at LUMS.\n",
    "\n",
    "Chat History: {history}\n",
    "\n",
    "Human: {question}\n",
    "\n",
    "Assistant123:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"context\", \"question\"],\n",
    "    template=context_qa  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    verbose=False,\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": prompt,\n",
    "        \"memory\": memory\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  .  .  .   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me: what are good courses that are math extensive?\n",
      "Chatbot: \n",
      "Based on the past reviews, courses that are math-extensive at LUMS include Introduction to Analysis I (MATH 205). Students who have taken this course have reported learning rigorous proofs behind calculus theory, covering sequences and series, continuity, and differentiability of functions. The course had quizzes, assignments, and both mid and final exams. The course instructor, Dr. Waqas, was praised for teaching effectively and providing notes on his website. If you enjoy proof-writing and want to build up your skills in rigorous mathematics, this course could be a good fit for you. It's also the basis for most advanced mathematics courses.\n",
      "Exiting ChatBot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Enter your question here (or type 'exit' to quit): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Exiting ChatBot. Goodbye!\")\n",
    "        break\n",
    "    print(\"  .  .  .   \")\n",
    "    #result = agent(user_input)\n",
    "\n",
    "    result = qa({'query': user_input})\n",
    "\n",
    "    # print(\"result:\", result)\n",
    "\n",
    "    answer = result['result']\n",
    "\n",
    "    # only keep the part followed by 'Assistant123:'\n",
    "    answer = answer.split('Assistant123:')[-1]\n",
    "    print(\"Me:\", user_input)\n",
    "    print(\"Chatbot:\", answer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
